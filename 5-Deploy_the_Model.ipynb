{"cells":[{"cell_type":"markdown","source":["# Creating a Real-Time Inferencing Service\n","\n","You've spent a lot of time in this course training and registering the flight delays machine learning model. Now it's time to deploy the model as a real-time service that clients can use to get predictions from new data.\n","\n","## Connect to Your Workspace\n","\n","The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n","\n","> **Note**: If you do not have a current authenticated session with your Azure subscription, you'll be prompted to authenticate. Follow the instructions to authenticate using the code provided."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["\n","import azureml.core\n","from azureml.core import Workspace\n","\n","# Load the workspace from the saved config file\n","ws = Workspace.from_config()\n","print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600436471160}}},{"cell_type":"markdown","source":["## Deploy a Model as a Web Service\n","\n","Now we have trained and registered the machine learning model that classifies flights based on the likelihood of them delaying. \n","This model could be used in a production environment such as an airline agency where passengers and scheduled pick-ups are notified about arrival delays. \n","To support this scenario, you will deploy the model as a web service.\n","\n","First, let's determine what models you have registered in the workspace."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Model\n","\n","for model in Model.list(ws):\n","    print(model.name, 'version:', model.version)\n","    for tag_name in model.tags:\n","        tag = model.tags[tag_name]\n","        print ('\\t',tag_name, ':', tag)\n","    for prop_name in model.properties:\n","        prop = model.properties[prop_name]\n","        print ('\\t',prop_name, ':', prop)\n","    print('\\n')"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420237889}}},{"cell_type":"markdown","source":["Right, now let's get the model that we want to deploy. By default, if we specify a model name, the latest version will be returned."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["model = ws.models['flight_delays_model']\n","print(model.name, 'version', model.version)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420238905}}},{"cell_type":"markdown","source":["We're going to create a web service to host this model, and this will require some code and configuration files; so let's create a folder for those."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import os\n","\n","folder_name = 'flight_delays_service'\n","\n","# Create a folder for the web service files\n","experiment_folder = './' + folder_name\n","os.makedirs(folder_name, exist_ok=True)\n","\n","print(folder_name, 'folder created.')"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420239062}}},{"cell_type":"markdown","source":["### Creating the Entry Script"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an *entry script* that will be deployed to the web service:"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%%writefile $folder_name/scoring_script.py\n","import json\n","import joblib\n","import numpy as np\n","from azureml.core.model import Model\n","\n","# Called when the service is loaded\n","def init():\n","    global model\n","    # Get the path to the deployed model file and load it\n","    model_path = Model.get_model_path('flight_delays_model')\n","    model = joblib.load(model_path)\n","\n","\n","# Called when a request is received\n","def run(raw_data):\n","    # Get the input data as a numpy array\n","    data = np.array(json.loads(raw_data)['data'])\n","    # Get a prediction from the model\n","    predictions = model.predict(data)\n","    # Get the corresponding classname for each prediction (0 or 1)\n","    classnames = ['no-delay', 'delay']\n","    predicted_classes = []\n","    for prediction in predictions:\n","        predicted_classes.append(classnames[prediction])\n","    # Return the predictions as JSON\n","    return json.dumps(predicted_classes)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires **scikit-learn, matplotlib and seaborn**, so we'll create a .yml file that tells the container host to install this into the environment."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core.conda_dependencies import CondaDependencies \n","\n","# Add the dependencies for our model (AzureML defaults is already included)\n","myenv = CondaDependencies()\n","myenv.add_conda_package(\"scikit-learn\")\n","myenv.add_pip_package(\"matplotlib\")\n","myenv.add_pip_package('seaborn')\n","\n","# Save the environment config as a .yml file\n","env_file = folder_name + \"/flight_delays_env.yml\"\n","with open(env_file,\"w\") as f:\n","    f.write(myenv.serialize_to_string())\n","print(\"Saved dependency info in\", env_file)\n","\n","# Print the .yml file\n","with open(env_file,\"r\") as f:\n","    print(f.read())"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420239217}}},{"source":["### Provision the AKS Cluster\n","\n","This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it.\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from azureml.core import ComputeTarget, AksCompute\n","\n","prov_config = AksCompute.provisioning_configuration()\n","\n","aks_name = 'my-aks-9' \n","# Create the cluster\n","aks_target = ComputeTarget.create(workspace = ws, \n","                                  name = aks_name, \n","                                  provisioning_configuration = prov_config)\n","\n","aks_target.wait_for_completion(show_output = True)\n","print(aks_target.provisioning_state)"]},{"cell_type":"markdown","source":["Now we're ready to deploy. We'll deploy the container  a service named **flight-delays-service**. The deployment process includes the following steps:\n","\n","1. Define an inference configuration, which includes the scoring and environment files required to load and use the model.\n","2. Define a deployment configuration that defines the execution environment in which the service will be hosted. In this case, an Azure Kubernetes Service.\n","3. Deploy the model as a web service.\n","4. Verify the status of the deployed service.\n","\n","> **More Information**: For more details about model deployment, and options for target execution environments, see the [documentation](https://docs.microsoft.com/en-gb/azure/machine-learning/service/how-to-deploy-and-where).\n","\n","\n","Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of **Healthy**."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core.webservice import AksWebservice\n","from azureml.core.model import InferenceConfig\n","from azureml.core import Model\n","\n","\n","# Configure the scoring environment\n","inference_config = InferenceConfig(runtime= \"python\",\n","                                   source_directory = folder_name,\n","                                   entry_script=\"scoring_script.py\",\n","                                   conda_file=\"flight_delays_env.yml\")\n","\n","deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, \n","                                                        memory_gb = 1, \n","                                                        compute_target_name='aks-compute',\n","                                                        auth_enabled=True,\n","                                                        autoscale_enabled=True)\n","\n","service_name = \"flight-service\"\n","\n","service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n","service.wait_for_deployment(True)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420357823}}},{"cell_type":"markdown","source":["## Use the Web Service\n","\n","With the service deployed, now you can consume it from a client application."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import json\n","\n","# This time our input is an array of two feature arrays\n","x_new = [[4, 19, 5, 4, 18, 36, 837, -3.0, 1138],\n","         [3, 76, 6, 4, 19, 36, 837, 98.0, 1234]]\n","\n","# Convert the array or arrays to a serializable list in a JSON document\n","input_json = json.dumps({\"data\": x_new})\n","\n","# Call the web service, passing the input data\n","predictions = service.run(input_data = input_json)\n","\n","# Get the predicted classes.\n","predicted_classes = json.loads(predictions)\n","   \n","for i in range(len(x_new)):\n","    print (\"Flight {}\".format(x_new[i]), predicted_classes[i] )"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420358572}}},{"cell_type":"markdown","source":["The code above uses the Azure ML SDK to connect to the containerized web service and use it to generate predictions from your flight delays classification model. In production, a model is likely to be consumed by business applications that do not use the Azure ML SDK, but simply make HTTP requests to the web service.\n","\n","Let's determine the URL to which these applications must submit their requests as well as the keys:"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["endpoint = service.scoring_uri\n","primary, secondary = service.get_keys()\n","print('PrirmaryKey: {} \\nSecondayKey: {} \\nEndpointUrl: {}'.format(primary,secondary,endpoint))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420358680}}},{"cell_type":"markdown","source":["Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es)."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import requests\n","import json\n","\n","endpoint = 'put-your-endpoint-url-here'\n","primary_key = 'put-primary-key-here'\n","\n","x_new = [[4, 19, 5, 4, 18, 36, 837, -3.0, 1138],\n","         [3, 76, 6, 4, 19, 36, 837, 98.0, 1234]]\n","\n","# Convert the array to a serializable list in a JSON document\n","input_json = json.dumps({\"data\": x_new})\n","\n","# Set the content type\n","request_headers = {\"Content-Type\": \"application/json\",\n","                   \"Authorization\": \"Bearer \" + primary_key}\n","\n","predictions = requests.post(endpoint, input_json, headers=request_headers)\n","\n","predicted_classes = json.loads(predictions.json())\n","\n","for i in range(len(x_new)):\n","    print(\"Flight {}\".format(x_new[i]), predicted_classes[i])\n"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600420825284}}},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}}],"metadata":{"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernel_info":{"name":"python3-azureml"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":2}