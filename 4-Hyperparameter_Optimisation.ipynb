{"cells":[{"cell_type":"markdown","source":["# Tuning Hyperparameters\n","\n","There are many machine learning algorithms that require *hyperparameters* (parameter values that influence training, but can't be determined from the training data itself). For example, when training a logistic regression model, you can use a *regularization rate* hyperparameter to counteract bias in the model; or when training a convolutional neural network, you can use hyperparameters like *learning rate* and *batch size* to control how weights are adjusted and how many data items are processed in a mini-batch respectively. The choice of hyperparameter values can significantly affect the performance of a trained model, or the time taken to train it; and often you need to try multiple combinations to find the optimal solution.\n","\n","In this case, you'll use a simple example of a logistic regression model with a single hyperparameter, but the principles apply to any kind of model you can train with Azure Machine Learning.\n","\n","## Connect to Your Workspace\n","\n","The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n","\n","> **Note**: You may be prompted to authenticate. Just copy the code and click the link provided to sign into your Azure subscription, and then return to this notebook."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import azureml.core\n","from azureml.core import Workspace\n","\n","# Load the workspace from the saved config file\n","ws = Workspace.from_config()\n","print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600428359322}}},{"cell_type":"markdown","source":["## Create a Training Script\n","\n","You're going to use a Python script to train a machine learning model based on the flight_delays data, so let's start by creating a folder for the script and data files."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import os\n","\n","experiment_folder = 'flight_delays_hyperdrive'\n","os.makedirs(experiment_folder, exist_ok=True)\n","\n","print('Folder ready.')"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600428359358}}},{"cell_type":"markdown","source":["### Interpreting Models\n","\n","You can use Azure Machine Learning to interpret a model by using an *explainer* that quantifies the amount of influence each feature contribues to the predicted label. There are many common explainers, each suitable for different kinds of modeling algorithm; but the basic approach to using them is the same.\n","\n","Run the following cell to ensure that you have the latest version of the Azure ML SDK installed, and in addition install the Azure ML Interpretability library. You can use this to interpret many typical kinds of model, even if they haven't been trained in an Azure ML experiment or registered in an Azure ML workspace.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["!pip install --upgrade azureml-sdk[notebooks,automl,explain]\n","!pip install --upgrade azureml-interpret"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["Now create the Python script to train the model. This must include:\n","\n","- A parameter for each hyperparameter you want to optimize (in this case, there's only the regularization hyperparameter)\n","- Code to log the performance metric you want to optimize for (in this case, you'll log both AUC and accuracy, so you can choose to optimize the model for either of these)"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%%writefile $experiment_folder/flight_delays_training.py\n","# Import libraries\n","import argparse\n","import json\n","import joblib\n","from azureml.core import Run\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Import libraries for model explanation\n","from azureml.contrib.interpret.explanation.explanation_client import ExplanationClient\n","from interpret.ext.blackbox import TabularExplainer\n","\n","\n","# Set regularization parameter\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n","args = parser.parse_args()\n","reg = args.reg_rate\n","\n","\n","\n","\n","# Get the experiment run context\n","run = Run.get_context()\n","\n","# load the diabetes dataset\n","print(\"Loading Data...\")\n","\n","\n","dataset = run.input_datasets['flight_delays_data'].to_pandas_dataframe().dropna() # Get the training data from the estimator input\n","\n","# Remove target leaker and features that are not useful\n","target_leakers = ['DepDel15','ArrDelay','Cancelled','Year']\n","dataset.drop(columns=target_leakers, axis=1, inplace=True)\n","\n","# convert some variables to categorical features\n","columns_as_categorical = ['OriginAirportID','DestAirportID','ArrDel15']\n","dataset[columns_as_categorical] = dataset[columns_as_categorical].astype('object')\n","\n","categorical_feature_mask = dataset.dtypes == object \n","categorical_cols = dataset.columns[categorical_feature_mask].tolist()\n","\n","le = LabelEncoder()\n","dataset[categorical_cols] = dataset[categorical_cols].apply(lambda col:le.fit_transform(col))\n","dataset = dataset.dropna()\n","\n","features = ['Month', 'DayofMonth', 'DayOfWeek', 'Carrier', 'OriginAirportID', 'DestAirportID', 'CRSDepTime', 'DepDelay', 'CRSArrTime']\n","labels = ['no-delay', 'delay']\n","\n","# Separate features and labels\n","X, y = dataset[features].values, dataset['ArrDel15'].values\n","\n","# Split data into training set and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n","\n","# Train a logistic regression model\n","print('Training a logistic regression model with regularization rate of', reg)\n","run.log('Regularization Rate',  np.float(reg))\n","model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n","\n","# calculate accuracy\n","y_hat = model.predict(X_test)\n","acc = np.average(y_hat == y_test)\n","print('Accuracy:', acc)\n","run.log('Accuracy', np.float(acc))\n","\n","# calculate AUC\n","y_scores = model.predict_proba(X_test)\n","auc = roc_auc_score(y_test,y_scores[:,1])\n","print('AUC: ' + str(auc))\n","run.log('AUC', np.float(auc))\n","\n","\n","# work on confusion matrix\n","\n","cnf_matrix = confusion_matrix(y_test, y_hat)\n","\n","cnf_matrix_list = cnf_matrix.tolist()\n","cnf_matrix_json_ = json.dumps(cnf_matrix_list)\n","run.log_confusion_matrix(name='Confusion_matrix', value=cnf_matrix_json_)\n","\n","class_names=[0,1] # name  of classes\n","fig, ax = plt.subplots()\n","tick_marks = np.arange(len(class_names))\n","plt.xticks(tick_marks, class_names)\n","plt.yticks(tick_marks, class_names)\n","# create heatmap\n","sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n","ax.xaxis.set_label_position(\"top\")\n","plt.tight_layout()\n","plt.title('Confusion matrix', y=1.1)\n","plt.ylabel('Actual label')\n","plt.xlabel('Predicted label')\n","plt.show()\n","run.log_image(name='confusion_matrix_img', plot=fig)\n","\n","\n","os.makedirs('outputs', exist_ok=True)\n","# note file saved in the outputs folder is automatically uploaded into experiment record\n","joblib.dump(value=model, filename='outputs/flight_delays_hyperdrive_model.pkl')\n","\n","# Get explanation\n","explainer = TabularExplainer(model, X_train, features=features, classes=labels)\n","explanation = explainer.explain_global(X_test)\n","\n","# Get an Explanation Client and upload the explanation\n","explain_client = ExplanationClient.from_run(run)\n","explain_client.upload_model_explanation(explanation, comment='Tabular Explanation')\n","\n","\n","run.complete()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["## Define an Environment\n","\n","Now you can run the experiment, using an estimator to run the training script. Note that the **azureml-interpret** library is included in the training environment so the script can create a **TabularExplainer**, and the **azureml-contrib-interpret** package is included so the script can use the **ExplainerClient** class."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Environment\n","from azureml.core.conda_dependencies import CondaDependencies\n","\n","# Create a Python environment for the experiment\n","flight_delays_hyperdrive_env = Environment(\"flight-delays-hyperdrive-experiment-env\")\n","flight_delays_hyperdrive_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n","flight_delays_hyperdrive_env.docker.enabled = True # Use a docker container\n","\n","# Create a set of package dependencies (conda or pip as required)\n","flight_delays_hyperdrive_packages = CondaDependencies.create(conda_packages=['scikit-learn', 'pandas'],\n","                                          pip_packages=['azureml-defaults', \n","                                          'azureml-dataprep[pandas]', \n","                                          'azureml-interpret',\n","                                          'azureml-contrib-interpret',\n","                                          'matplotlib', \n","                                          'seaborn'])\n","\n","# Add the dependencies to the environment\n","flight_delays_hyperdrive_env.python.conda_dependencies = flight_delays_hyperdrive_packages\n","\n","print(flight_delays_hyperdrive_env.name, 'defined.')\n","\n","# Register the environment\n","flight_delays_hyperdrive_env.register(workspace=ws)\n","print(flight_delays_hyperdrive_env.name, 'registered.')"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600428379134}}},{"cell_type":"markdown","source":["## Run a *Hyperdrive* Experiment\n","\n","Azure Machine Learning includes a hyperparameter tuning capability through *Hyperdrive* experiments. These experiments launch multiple child runs, each with a different hyperparameter combination. The run producing the best model (as determined by the logged target performance metric for which you want to optimize) can be identified, and its trained model selected for registration and deployment."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Experiment, Environment\n","from azureml.train.sklearn import SKLearn\n","from azureml.train.hyperdrive import GridParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal, choice\n","from azureml.widgets import RunDetails\n","\n","\n","# Get the environment\n","registered_env = Environment.get(ws, 'flight-delays-hyperdrive-experiment-env')\n","\n","# specify cluster name\n","cluster_name = \"aml-cluster\"\n","\n","# Get the training dataset\n","flight_delays_ds = ws.datasets.get(\"flight_delays_data\")\n","\n","\n","# Sample a range of parameter values\n","params = GridParameterSampling(\n","    {\n","        # There's only one parameter, so grid sampling will try each value - with multiple parameters it would try every combination\n","        '--regularization': choice(0.001, 0.005, 0.01, 0.05, 0.1, 1.0)\n","    }\n",")\n","\n","\n","# Create an estimator that uses the remote compute\n","hyper_estimator = SKLearn(source_directory=experiment_folder,\n","                          inputs=[flight_delays_ds.as_named_input('flight_delays_data')], # Pass the dataset as an input...\n","                          environment_definition = registered_env,\n","                        #   pip_packages=['azureml-sdk'], # ...so we need azureml-dataprep (it's in the SDK!)\n","                          entry_script='flight_delays_training.py',\n","                          compute_target = cluster_name,)\n","\n","# Configure hyperdrive settings\n","hyperdrive = HyperDriveConfig(estimator=hyper_estimator, \n","                          hyperparameter_sampling=params, \n","                          policy=None, \n","                          primary_metric_name='AUC', \n","                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n","                          max_total_runs=6,\n","                          max_concurrent_runs=4)\n","\n","# Run the experiment\n","experiment = Experiment(workspace = ws, name = 'flight-delays-training-hyperdrive')\n","run = experiment.submit(config=hyperdrive)\n","\n","# Show the status in the notebook as the experiment runs\n","RunDetails(run).show()\n","run.wait_for_completion()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600428177122}}},{"cell_type":"markdown","source":["You can view the experiment run status in the widget above. You can also view the main Hyperdrive experiment run and its child runs in [Azure Machine Learning studio](https://ml.azure.com).\n","\n","> **Note**: The widget may not refresh. You'll see summary information displayed below the widget when the run has completed.\n","\n","## Determine the Best Performing Run\n","\n","When all of the runs have finished, you can find the best one based on the performance metric you specified (in this case, the one with the best AUC)."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["for child_run in run.get_children_sorted_by_primary_metric():\n","    print(child_run)\n","\n","best_run = run.get_best_run_by_primary_metric()\n","best_run_metrics = best_run.get_metrics()\n","parameter_values = best_run.get_details() ['runDefinition']['arguments']\n","\n","print('Best Run Id: ', best_run.id)\n","print(' -AUC:', best_run_metrics['AUC'])\n","print(' -Accuracy:', best_run_metrics['Accuracy'])\n","print(' -Regularization Rate:',parameter_values)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600430341979}}},{"cell_type":"markdown","source":["Now that you've found the best run, you can register the model it trained."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Model\n","\n","# Register the model\n","best_run.register_model(model_path='outputs/flight_delays_hyperdrive_model.pkl', model_name='flight_delays_hyperdrive_model',\n","                   tags={'Training context':'Hyperdrive Flight delays model'},\n","                   properties={'AUC': best_run.get_metrics()['AUC'], 'Accuracy': best_run.get_metrics()['Accuracy']})\n","\n","# List registered models\n","for model in Model.list(ws):\n","    print(model.name, 'version:', model.version)\n","    for tag_name in model.tags:\n","        tag = model.tags[tag_name]\n","        print ('\\t',tag_name, ':', tag)\n","    for prop_name in model.properties:\n","        prop = model.properties[prop_name]\n","        print ('\\t',prop_name, ':', prop)\n","    print('\\n')"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600430349477}}},{"cell_type":"markdown","source":["## Retrieve the Feature Importance Values\n","\n","With the experiment run completed, you can use the **ExplanationClient** class to retrieve the feature importance from the explanation registered for the run."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.contrib.interpret.explanation.explanation_client import ExplanationClient\n","\n","# Get the feature explanations\n","client = ExplanationClient.from_run(run)\n","engineered_explanations = client.download_model_explanation()\n","feature_importances = engineered_explanations.get_feature_importance_dict()\n","\n","# Overall feature importance\n","print('Feature\\tImportance')\n","for key, value in feature_importances.items():\n","    print(key, '\\t', value)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}}],"metadata":{"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernel_info":{"name":"python3-azureml"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":2}